# Planner model endpoint configuration
VITE_PLANNER_MODEL_ENDPOINT=https://aryan-cs--deepseek-r1-32b-openai-server.modal.run
VITE_PLANNER_CONTEXT_ENDPOINT=
VITE_PLANNER_MODEL_ID=deepseek-r1
VITE_PLANNER_API_KEY=

# Frontend -> Vite proxy paths
VITE_USE_PLANNER_PROXY=true
VITE_PLANNER_PROXY_PATH=/api/planner/chat
VITE_EXA_PROXY_PATH=/api/exa/search

# Planner context ingestion limits
VITE_PLANNER_CONTEXT_MAX_TOTAL_CHARS=26000
VITE_PLANNER_CONTEXT_MAX_FILE_CHARS=5000

# Exa proxy/server configuration
EXA_API_KEY=499b1533-c1df-4506-843b-6b68a27bdbf1
EXA_API_ENDPOINT=https://api.exa.ai/search
EXA_PROXY_PATH=/api/exa/search

# Modal smoke test URL used by server.py local entrypoint
DEEPSEEK_SMOKE_TEST_URL=https://aryan-cs--deepseek-r1-32b-openai-server.modal.run/v1/chat/completions

# Modal serving config used by server.py
MODAL_APP_NAME=deepseek-r1-32b
DEEPSEEK_MODEL_ID=deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
DEEPSEEK_SERVED_MODEL_NAME=deepseek-r1
DEEPSEEK_MODEL_DIR=/model
DEEPSEEK_VOLUME_NAME=deepseek-r1-32b-weights
VLLM_PORT=8000
DEEPSEEK_GPU=A100-80GB:2
DEEPSEEK_TP=2
DEEPSEEK_MAX_MODEL_LEN=32768
DEEPSEEK_GPU_MEMORY_UTIL=0.92